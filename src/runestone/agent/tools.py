"""
Tool definitions for the agent using LangChain's @tool decorator.
"""

import asyncio
import json
import logging
from dataclasses import dataclass
from typing import Literal

from langchain.tools import ToolRuntime
from langchain_core.tools import tool
from pydantic import BaseModel, Field, field_validator

from runestone.db.models import User
from runestone.services.user_service import UserService
from runestone.services.vocabulary_service import VocabularyService
from runestone.utils.merge import deep_merge

logger = logging.getLogger(__name__)


class WordPrioritisationItem(BaseModel):
    """Input for a single word to prioritize."""

    word_phrase: str = Field(..., description="The Swedish word or phrase")
    translation: str = Field(..., description="Translation of the word_phrase (concise)")
    example_phrase: str = Field(..., description="Example sentence in Swedish")

    @field_validator("word_phrase", "translation", "example_phrase", mode="before")
    @classmethod
    def decode_unicode_escapes(cls, v: str) -> str:
        """Fix double-escaped unicode characters often generated by LLMs."""
        if isinstance(v, str) and "\\u" in v:
            try:
                # v.encode('utf-8') converts 'f\\u00f6...' to bytes b'f\\u00f6...'
                # .decode('unicode_escape') interprets \\u00f6 as รถ
                return v.encode("utf-8").decode("unicode_escape")
            except Exception:
                return v
        return v


class WordPrioritisationInput(BaseModel):
    """Input for prioritizing words for learning."""

    words: list[WordPrioritisationItem] = Field(..., description="List of words to prioritize")


@dataclass
class AgentContext:
    """Context passed to agent tools at runtime."""

    user: User
    # we can't use DI of FastAPI here, so had to put the service to context
    user_service: UserService
    vocabulary_service: VocabularyService


@tool
def update_memory(
    category: Literal["personal_info", "areas_to_improve", "knowledge_strengths"],
    operation: Literal["merge", "replace"],
    data: dict,
    runtime: ToolRuntime[AgentContext],
) -> str:
    """
    Update the student's memory profile with new information.

    Use this tool to store long-term information about the student:
    - personal_info: goals, preferences, name, background
    - areas_to_improve: struggling concepts, recurring mistakes
    - knowledge_strengths: mastered topics, successful applications

    Args:
        category: Which memory category to update
        operation: 'merge' to add/update keys, 'replace' to overwrite entirely
        data: JSON data to store (use descriptive keys like 'grammar_struggles')
        runtime: Tool runtime context containing user and user_service

    Returns:
        Confirmation message
    """
    user = runtime.context.user
    user_service: UserService = runtime.context.user_service

    logger.info(f"Updating memory for user {user.id}: {category}")

    try:
        final_data = data
        if operation == "merge":
            # Get current data to merge with
            current_json = getattr(user, category)
            current_dict = json.loads(current_json) if current_json else {}
            final_data = deep_merge(current_dict, data)

        logger.info(f"Final data for {category}: {final_data}")
        # Update memory via service
        user_service.update_user_memory(user, category, final_data)
        logger.info(f"Successfully updated {category} for user {user.id}")
        return f"Successfully updated {category}."
    except Exception as e:
        logger.error(f"Error updating memory for user {user.id}: {e}")
        return f"Error updating memory: {str(e)}"


@tool(args_schema=WordPrioritisationInput)
async def prioritize_words_for_learning(
    words: list[WordPrioritisationItem],
    runtime: ToolRuntime[AgentContext],
) -> str:
    """
    Mark words for priority learning. Use when student uses another language
    to express a word or constantly makes errors writing a word.

    This tool runs in the background - returns immediately.
    For each word:
    - If deleted: restores it and marks for priority
    - If exists: marks for priority
    - If new: creates it with priority flag

    Args:
        words: List of words to prioritize for learning
        runtime: Tool runtime context

    Returns:
        Immediate acknowledgment message
    """
    user = runtime.context.user
    vocab_service = runtime.context.vocabulary_service

    async def process_words():
        for word_item in words:
            try:
                vocab_service.upsert_priority_word(
                    word_phrase=word_item.word_phrase,
                    translation=word_item.translation,
                    example_phrase=word_item.example_phrase,
                    user_id=user.id,
                )
                logger.info(f"Processed priority word: {word_item.word_phrase}")
            except Exception as e:
                logger.error(f"Failed to process {word_item.word_phrase}: {e}")

    asyncio.create_task(process_words())
    return f"Processing {len(words)} word(s) for priority learning in background."
